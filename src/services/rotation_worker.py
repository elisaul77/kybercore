"""
Rotation Worker Service
Procesa archivos STL en batch: rotaci√≥n + laminado de forma as√≠ncrona y paralela
Implementa retry logic, manejo de errores robusto y observabilidad
"""

import asyncio
import aiohttp
import json
import time
import uuid
import os
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

from src.models.task_models import (
    TaskStatus, TaskStatusEnum, TaskProgress, FileProcessingResult
)
from src.controllers.print_flow_controller import (
    load_wizard_session, save_wizard_session, find_stl_file_path
)
from src.services.plating_service import plating_service
import logging

logger = logging.getLogger(__name__)


class RotationWorker:
    """
    Worker que maneja el procesamiento batch de archivos STL.
    Implementa paralelizaci√≥n, retry logic y manejo de errores robusto.
    """
    
    def __init__(self, max_concurrent: int = 3, max_retries: int = 3, retry_delay: int = 2):
        """
        Args:
            max_concurrent: N√∫mero m√°ximo de archivos a procesar simult√°neamente
            max_retries: N√∫mero de reintentos para operaciones fallidas
            retry_delay: Segundos de espera entre reintentos
        """
        self.max_concurrent = max_concurrent
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.executor = ThreadPoolExecutor(max_workers=max_concurrent)
        self.tasks: Dict[str, TaskStatus] = {}
        
        logger.info(f"RotationWorker inicializado: max_concurrent={max_concurrent}, max_retries={max_retries}")
    
    async def process_batch(
        self, 
        task_id: str,
        session_id: str,
        files: List[str],
        rotation_config: Dict[str, Any],
        profile_config: Dict[str, Any],
        plating_config: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        Procesa m√∫ltiples archivos en paralelo con control de concurrencia.
        Soporta auto-plating para combinar m√∫ltiples piezas en un solo plato.
        
        Args:
            task_id: ID √∫nico de la tarea
            session_id: ID de sesi√≥n del wizard
            files: Lista de nombres de archivos a procesar
            rotation_config: Configuraci√≥n de auto-rotaci√≥n
            profile_config: Configuraci√≥n del perfil de laminado
            plating_config: (Opcional) Configuraci√≥n de auto-plating para combinar piezas
        """
        start_time = time.time()
        
        try:
            logger.info(f"üì¶ Iniciando procesamiento batch: task_id={task_id}, archivos={len(files)}")
            
            # Normalizar lista de archivos (puede venir como strings o dicts)
            normalized_files = []
            for f in files:
                if isinstance(f, str):
                    normalized_files.append(f)
                elif isinstance(f, dict):
                    # Si viene como dict, extraer el nombre del archivo
                    normalized_files.append(f.get('nombre', f.get('filename', f.get('name', str(f)))))
                else:
                    logger.warning(f"‚ö†Ô∏è  Tipo de archivo no reconocido: {type(f)}, usando str()")
                    normalized_files.append(str(f))
            
            logger.info(f"üìã Archivos normalizados: {normalized_files}")
            
            # Crear TaskStatus inicial
            self.tasks[task_id] = TaskStatus(
                task_id=task_id,
                session_id=session_id,
                status=TaskStatusEnum.PROCESSING,
                progress=TaskProgress(
                    total_files=len(normalized_files),
                    completed=0,
                    failed=0,
                    in_progress=0,
                    percentage=0.0
                ),
                created_at=datetime.now(),
                started_at=datetime.now()
            )
            
            # Crear directorio temporal para la sesi√≥n
            session_dir = Path(f"/tmp/kybercore_processing/{session_id}")
            session_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"üìÅ Directorio temporal creado: {session_dir}")
            
            # üé® FLUJO OPTIMIZADO: Auto-Rotaci√≥n + Auto-Plating
            # 1. Si rotation y plating est√°n habilitados ‚Üí rotar cada pieza ANTES de combinar
            # 2. Si solo rotation ‚Üí rotar y procesar individualmente  
            # 3. Si solo plating ‚Üí combinar originales directamente
            
            files_to_process = normalized_files  # Por defecto, procesar todos los archivos individualmente
            plating_enabled = plating_config and plating_config.get('enabled', False)
            rotation_enabled = rotation_config.get('enabled', False)
            combined_stl_path = None
            
            # üîÑ PRE-PROCESAMIENTO: Aplicar auto-rotaci√≥n a cada pieza si est√° habilitado (ANTES del plating)
            if rotation_enabled and len(normalized_files) >= 1:
                logger.info(f"üîÑ Auto-Rotaci√≥n HABILITADA: Pre-procesando {len(normalized_files)} piezas")
                
                for filename in normalized_files:
                    try:
                        # Leer archivo original
                        stl_path = find_stl_file_path(filename, session_id)
                        if not stl_path or not Path(stl_path).exists():
                            logger.warning(f"‚ö†Ô∏è  No se encontr√≥: {filename}")
                            continue
                        
                        with open(stl_path, 'rb') as f:
                            file_bytes = f.read()
                        
                        logger.info(f"   üîÑ Rotando {filename}...")
                        logger.info(f"   üéØ Config de rotaci√≥n: threshold={rotation_config.get('improvement_threshold', 'NO DEFINIDO')}")
                        
                        # Aplicar rotaci√≥n
                        rotated_bytes, rotation_info = await self._rotate_file_with_retry(
                            file_bytes=file_bytes,
                            filename=filename,
                            config=rotation_config
                        )
                        
                        if rotation_info and rotation_info.get("applied"):
                            # Guardar pieza rotada en session_dir
                            rotated_path = session_dir / f"rotated_{filename}"
                            with open(rotated_path, 'wb') as f:
                                f.write(rotated_bytes)
                            
                            logger.info(
                                f"   ‚úÖ Rotada: {rotation_info['degrees']}, "
                                f"mejora: {rotation_info['improvement']:.2f}%"
                            )
                        else:
                            # Si no se aplic√≥ rotaci√≥n, copiar el original
                            rotated_path = session_dir / f"rotated_{filename}"
                            with open(rotated_path, 'wb') as f:
                                f.write(file_bytes)
                            logger.info(f"   ‚óã Sin mejora, usando original")
                    
                    except Exception as e:
                        logger.error(f"   ‚ùå Error rotando {filename}: {str(e)}")
                        # Copiar original si falla la rotaci√≥n
                        try:
                            rotated_path = session_dir / f"rotated_{filename}"
                            with open(stl_path, 'rb') as f:
                                with open(rotated_path, 'wb') as f_out:
                                    f_out.write(f.read())
                        except:
                            pass
            
            # üé® AUTO-PLATING: Combinar m√∫ltiples piezas (rotadas o originales)
            if plating_enabled and len(normalized_files) > 1:
                logger.info(f"üé® Auto-Plating HABILITADO: Combinando {len(normalized_files)} piezas")
                
                # Si se aplic√≥ rotaci√≥n, usar archivos rotados; sino, usar originales
                stl_paths = []
                for filename in normalized_files:
                    if rotation_enabled:
                        # Usar archivo rotado
                        rotated_path = session_dir / f"rotated_{filename}"
                        if rotated_path.exists():
                            stl_paths.append(str(rotated_path))
                            logger.info(f"   üì¶ Usando rotado: {filename}")
                        else:
                            # Fallback al original
                            stl_path = find_stl_file_path(filename, session_id)
                            if stl_path and Path(stl_path).exists():
                                stl_paths.append(stl_path)
                                logger.warning(f"   ‚ö†Ô∏è  Usando original: {filename}")
                    else:
                        # Usar archivo original
                        stl_path = find_stl_file_path(filename, session_id)
                        if stl_path and Path(stl_path).exists():
                            stl_paths.append(stl_path)
                        else:
                            logger.warning(f"‚ö†Ô∏è  No se encontr√≥: {filename}")
                
                if len(stl_paths) >= 2:
                    # Configuraci√≥n de plating
                    bed_size = profile_config.get('bed_size', [220.0, 220.0])
                    algorithm = plating_config.get('algorithm', 'bin-packing')
                    spacing = plating_config.get('spacing', 3.0)
                    enable_nesting = plating_config.get('enable_nesting', False)  # üî¨ Nesting 3D
                    
                    logger.info(f"üé® Configuraci√≥n: bed={bed_size}, algoritmo={algorithm}, spacing={spacing}mm, nesting={enable_nesting}")
                    
                    # Combinar archivos (ya rotados si rotation_enabled=True)
                    success, message, metadata = plating_service.combine_stl_files(
                        stl_files=stl_paths,
                        output_path=str(session_dir / "combined_plating.stl"),
                        bed_size=tuple(bed_size),
                        spacing=spacing,
                        algorithm=algorithm,
                        enable_nesting=enable_nesting
                    )
                    
                    if success:
                        combined_stl_path = str(session_dir / "combined_plating.stl")
                        files_to_process = ["combined_plating.stl"]  # Procesar solo el combinado
                        
                        # Actualizar TaskStatus
                        self.tasks[task_id].progress.total_files = 1
                        
                        logger.info(f"‚úÖ Plating exitoso: {message}")
                        logger.info(f"üìä Metadata: {metadata}")
                        
                        # Guardar info en sesi√≥n
                        session_data = load_wizard_session(session_id)
                        if session_data:
                            session_data["plating_info"] = {
                                "enabled": True,
                                "rotation_applied_first": rotation_enabled,
                                "original_files": normalized_files,
                                "combined_file": "combined_plating.stl",
                                "algorithm": algorithm,
                                "metadata": metadata,
                                "message": message
                            }
                            save_wizard_session(session_id, session_data)
                    else:
                        logger.error(f"‚ùå Error en plating: {message}")
                        logger.warning(f"‚ö†Ô∏è  Continuando con procesamiento individual")
                else:
                    logger.warning(f"‚ö†Ô∏è  No hay suficientes archivos v√°lidos para plating")
            elif plating_enabled and len(normalized_files) == 1:
                logger.info(f"‚ÑπÔ∏è  Plating habilitado pero solo hay 1 archivo")
            
            # Procesar archivos en paralelo con sem√°foro para limitar concurrencia
            semaphore = asyncio.Semaphore(self.max_concurrent)
            
            async def process_with_semaphore(filename: str) -> FileProcessingResult:
                """Wrapper para controlar concurrencia"""
                async with semaphore:
                    # Actualizar contador de archivos en progreso
                    self.tasks[task_id].progress.in_progress += 1
                    
                    try:
                        result = await self._process_single_file(
                            filename=filename,
                            session_id=session_id,
                            session_dir=session_dir,
                            rotation_config=rotation_config,
                            profile_config=profile_config,
                            task_id=task_id
                        )
                        return result
                    finally:
                        # Decrementar contador al finalizar
                        self.tasks[task_id].progress.in_progress -= 1
            
            # Ejecutar en paralelo todas las tareas
            logger.info(f"üöÄ Procesando {len(files_to_process)} archivos en paralelo (m√°x {self.max_concurrent} simult√°neos)")
            results = await asyncio.gather(
                *[process_with_semaphore(f) for f in files_to_process],
                return_exceptions=True
            )
            
            # Procesar resultados
            successful_results = []
            failed_results = []
            
            for filename, result in zip(files_to_process, results):
                if isinstance(result, Exception):
                    # Excepci√≥n no capturada
                    error_msg = f"Error inesperado procesando {filename}: {str(result)}"
                    logger.error(error_msg)
                    failed_results.append(FileProcessingResult(
                        filename=filename,
                        success=False,
                        error=error_msg
                    ))
                    self.tasks[task_id].errors.append(error_msg)
                elif result.success:
                    successful_results.append(result)
                else:
                    failed_results.append(result)
                    if result.error:
                        self.tasks[task_id].errors.append(f"{filename}: {result.error}")
                
                # Actualizar progreso
                self.tasks[task_id].progress.completed = len(successful_results)
                self.tasks[task_id].progress.failed = len(failed_results)
                self.tasks[task_id].progress.percentage = (
                    (len(successful_results) + len(failed_results)) / len(files_to_process) * 100
                )
            
            # Actualizar sesi√≥n con resultados
            session_data = load_wizard_session(session_id)
            if session_data:
                # Construir resumen de procesamiento
                processing_summary = {
                    "total_files": len(files_to_process),
                    "successful": len(successful_results),
                    "failed": len(failed_results)
                }
                
                # Si se us√≥ plating, agregar info adicional
                if plating_enabled and combined_stl_path:
                    processing_summary["plating_used"] = True
                    processing_summary["original_files_count"] = len(normalized_files)
                    processing_summary["combined_file"] = "combined_plating.stl"
                
                session_data["stl_processing"] = {
                    "task_id": task_id,
                    "successful": [r.dict() for r in successful_results],
                    "failed": [r.dict() for r in failed_results],
                    "processing_summary": processing_summary,
                    "completed_at": datetime.now().isoformat()
                }
                # ‚úÖ IMPORTANTE: Marcar el paso como completado
                completed_steps = session_data.get("completed_steps", [])
                if "stl_processing" not in completed_steps:
                    session_data["completed_steps"] = completed_steps + ["stl_processing"]
                session_data["current_step"] = "validation"
                save_wizard_session(session_id, session_data)
            
            # Actualizar estado de la tarea
            self.tasks[task_id].status = TaskStatusEnum.COMPLETED
            self.tasks[task_id].results = successful_results + failed_results
            self.tasks[task_id].completed_at = datetime.now()
            
            elapsed = time.time() - start_time
            logger.info(
                f"‚úÖ Procesamiento batch completado: "
                f"task_id={task_id}, "
                f"exitosos={len(successful_results)}, "
                f"fallidos={len(failed_results)}, "
                f"tiempo={elapsed:.2f}s"
            )
            
        except Exception as e:
            error_msg = f"Error cr√≠tico en procesamiento batch: {str(e)}"
            logger.error(error_msg, exc_info=True)
            
            self.tasks[task_id].status = TaskStatusEnum.FAILED
            self.tasks[task_id].error_message = error_msg
            self.tasks[task_id].completed_at = datetime.now()
    
    async def _process_single_file(
        self,
        filename: str,
        session_id: str,
        session_dir: Path,
        rotation_config: Dict[str, Any],
        profile_config: Dict[str, Any],
        task_id: str
    ) -> FileProcessingResult:
        """
        Procesa un archivo individual: rotar ‚Üí laminar ‚Üí guardar.
        
        Args:
            filename: Nombre del archivo STL
            session_id: ID de sesi√≥n
            session_dir: Directorio temporal para guardar archivos
            rotation_config: Configuraci√≥n de rotaci√≥n
            profile_config: Configuraci√≥n de perfil
            task_id: ID de la tarea (para logging)
            
        Returns:
            FileProcessingResult con el resultado del procesamiento
        """
        file_start_time = time.time()
        
        try:
            logger.info(f"üìÑ Procesando archivo: {filename} (task: {task_id})")
            
            # Normalizar configuraciones (pueden venir como string, dict, o BaseModel)
            if isinstance(rotation_config, str):
                try:
                    import json
                    rotation_config = json.loads(rotation_config)
                except:
                    rotation_config = {"enabled": False}
            elif not isinstance(rotation_config, dict):
                # Si es un modelo Pydantic, convertir a dict
                rotation_config = dict(rotation_config) if hasattr(rotation_config, '__dict__') else {"enabled": False}
            
            if isinstance(profile_config, str):
                try:
                    import json
                    profile_config = json.loads(profile_config)
                except:
                    profile_config = {}
            elif not isinstance(profile_config, dict):
                profile_config = dict(profile_config) if hasattr(profile_config, '__dict__') else {}
            
            logger.info(f"   ‚úì Configuraciones normalizadas: rotation_enabled={rotation_config.get('enabled', False)}")
            
            # 1. Leer archivo original
            try:
                # Cargar sesi√≥n para obtener informaci√≥n del proyecto
                session_data = load_wizard_session(session_id)
                if not session_data:
                    raise ValueError(f"Sesi√≥n no encontrada: {session_id}")
                
                # **Caso especial: Archivo combinado de plating**
                if filename == "combined_plating.stl":
                    # El archivo est√° en session_dir, no en el proyecto
                    combined_path = session_dir / "combined_plating.stl"
                    if not combined_path.exists():
                        raise FileNotFoundError(f"Archivo combinado no encontrado: {combined_path}")
                    
                    with open(combined_path, 'rb') as f:
                        file_bytes = f.read()
                    
                    logger.info(f"   ‚úì Archivo combinado le√≠do: {len(file_bytes)} bytes")
                
                else:
                    # **Caso normal: Archivo original del proyecto**
                    # Obtener project_id y cargar proyecto
                    project_id = session_data.get("project_id")
                    if not project_id:
                        raise ValueError(f"project_id no encontrado en sesi√≥n {session_id}")
                    
                    logger.info(f"   üìã Buscando proyecto con ID: {project_id} (tipo: {type(project_id)})")
                    
                    # Cargar informaci√≥n del proyecto
                    from src.controllers.gallery_controller import load_projects_data
                    projects_data = load_projects_data()
                    projects = projects_data.get("proyectos", [])  # Usar "proyectos" (espa√±ol)
                    
                    logger.info(f"   üìä Total proyectos disponibles: {len(projects)}")
                    if len(projects) > 0:
                        logger.info(f"   üìä IDs disponibles: {[p.get('id') for p in projects[:5]]}")
                    
                    project = next((p for p in projects if p.get("id") == int(project_id)), None)
                    
                    if not project:
                        raise ValueError(f"Proyecto {project_id} no encontrado")
                    
                    # Ahora s√≠ buscar el archivo (puede ser STL, 3MF, etc.)
                    original_path = find_stl_file_path(project, filename)
                    if not original_path or not Path(original_path).exists():
                        raise FileNotFoundError(f"Archivo 3D no encontrado: {filename}")
                    
                    with open(original_path, 'rb') as f:
                        file_bytes = f.read()
                    
                    logger.info(f"   ‚úì Archivo le√≠do: {len(file_bytes)} bytes")
                    
                    # üîÑ Si es archivo 3MF, convertirlo a STL para el slicer
                    if filename.lower().endswith('.3mf'):
                        logger.info(f"   üîÑ Convirtiendo 3MF a STL...")
                        try:
                            import trimesh
                            import io
                            
                            # Cargar el archivo 3MF
                            mesh = trimesh.load(io.BytesIO(file_bytes), file_type='3mf')
                            
                            # Si es una escena con m√∫ltiples objetos, combinarlos
                            if isinstance(mesh, trimesh.Scene):
                                meshes = [geom for geom in mesh.geometry.values()]
                                if len(meshes) > 1:
                                    mesh = trimesh.util.concatenate(meshes)
                                elif len(meshes) == 1:
                                    mesh = meshes[0]
                                else:
                                    raise ValueError("No se encontraron geometr√≠as en el archivo 3MF")
                            
                            # Convertir a STL
                            stl_bytes = trimesh.exchange.stl.export_stl(mesh)
                            file_bytes = stl_bytes
                            
                            # Actualizar el nombre del archivo para el slicer
                            filename = filename.replace('.3mf', '.stl')
                            
                            logger.info(f"   ‚úÖ Conversi√≥n 3MF‚ÜíSTL exitosa: {len(file_bytes)} bytes")
                        except Exception as conv_error:
                            logger.error(f"   ‚ùå Error convirtiendo 3MF a STL: {conv_error}")
                            raise ValueError(f"No se pudo convertir el archivo 3MF: {conv_error}")
            except Exception as e:
                error_msg = f"Error leyendo archivo: {str(e)}"
                logger.error(f"   ‚úó {error_msg}")
                return FileProcessingResult(
                    filename=filename,
                    success=False,
                    error=error_msg
                )
            
            # 2. Aplicar auto-rotaci√≥n si est√° habilitada
            # ‚ö†Ô∏è IMPORTANTE: Si el archivo es combined_plating.stl, NO rotar
            # (las piezas individuales ya fueron rotadas antes de combinarse)
            rotation_info = None
            skip_rotation = (filename == "combined_plating.stl")
            
            if rotation_config.get("enabled", False) and not skip_rotation:
                try:
                    logger.info(f"   üîÑ Aplicando auto-rotaci√≥n (umbral: {rotation_config.get('improvement_threshold', 5)}%)")
                    
                    rotated_bytes, rotation_info = await self._rotate_file_with_retry(
                        file_bytes=file_bytes,
                        filename=filename,
                        config=rotation_config
                    )
                    
                    if rotation_info and rotation_info.get("applied"):
                        # Guardar archivo rotado
                        rotated_path = session_dir / f"rotated_{filename}"
                        with open(rotated_path, 'wb') as f:
                            f.write(rotated_bytes)
                        
                        file_to_slice = rotated_bytes
                        logger.info(
                            f"   ‚úì Rotaci√≥n aplicada: {rotation_info['degrees']}, "
                            f"mejora: {rotation_info['improvement']:.2f}%"
                        )
                    else:
                        file_to_slice = file_bytes
                        logger.info(f"   ‚óã Rotaci√≥n no aplicada (mejora insuficiente)")
                        
                except Exception as e:
                    error_msg = f"Error en rotaci√≥n: {str(e)}"
                    logger.warning(f"   ‚ö† {error_msg}, usando archivo original")
                    file_to_slice = file_bytes
                    rotation_info = {"applied": False, "error": error_msg}
            else:
                file_to_slice = file_bytes
                if skip_rotation:
                    logger.info(f"   ‚óã Archivo combinado (piezas ya rotadas individualmente)")
                else:
                    logger.info(f"   ‚óã Auto-rotaci√≥n deshabilitada")
            
            # 3. Laminar archivo (rotado o original)
            try:
                logger.info(f"   ‚öôÔ∏è  Laminando archivo...")
                
                gcode_bytes = await self._slice_file_with_retry(
                    file_bytes=file_to_slice,
                    filename=filename,
                    profile_config=profile_config
                )
                
                # Guardar G-code
                gcode_filename = filename.replace('.stl', '.gcode')
                gcode_path = session_dir / f"gcode_{session_id}_{gcode_filename}"
                
                with open(gcode_path, 'wb') as f:
                    f.write(gcode_bytes)
                
                logger.info(f"   ‚úì G-code generado: {len(gcode_bytes)} bytes")
                
            except Exception as e:
                error_msg = f"Error laminando archivo: {str(e)}"
                logger.error(f"   ‚úó {error_msg}")
                return FileProcessingResult(
                    filename=filename,
                    success=False,
                    rotated=rotation_info is not None and rotation_info.get("applied", False),
                    rotation_info=rotation_info,
                    error=error_msg
                )
            
            # Calcular tiempo de procesamiento
            processing_time = time.time() - file_start_time
            
            logger.info(f"   ‚úÖ Archivo completado en {processing_time:.2f}s")
            
            return FileProcessingResult(
                filename=filename,
                success=True,
                rotated=rotation_info is not None and rotation_info.get("applied", False),
                rotation_info=rotation_info,
                gcode_path=str(gcode_path),
                gcode_size=len(gcode_bytes),
                processing_time_seconds=processing_time
            )
            
        except Exception as e:
            error_msg = f"Error inesperado: {str(e)}"
            logger.error(f"   ‚úó {error_msg}", exc_info=True)
            return FileProcessingResult(
                filename=filename,
                success=False,
                error=error_msg
            )
    
    async def _rotate_file_with_retry(
        self, 
        file_bytes: bytes, 
        filename: str, 
        config: Dict[str, Any]
    ) -> Tuple[bytes, Optional[Dict[str, Any]]]:
        """
        Llama a APISLICER para rotar el archivo con retry logic.
        
        Args:
            file_bytes: Contenido del archivo STL
            filename: Nombre del archivo
            config: Configuraci√≥n de rotaci√≥n
            
        Returns:
            Tupla (bytes del archivo rotado, info de rotaci√≥n)
        """
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    # Preparar FormData
                    data = aiohttp.FormData()
                    data.add_field('file', file_bytes, filename=filename, content_type='application/octet-stream')
                    
                    # Agregar par√°metros de configuraci√≥n
                    # IMPORTANTE: Usar 'in' para detectar si la clave existe, no confiar solo en .get()
                    # porque improvement_threshold=0 es un valor v√°lido y debe respetarse
                    threshold = config.get('improvement_threshold', 5.0) if 'improvement_threshold' in config else 5.0
                    
                    data.add_field('method', config.get('method', 'auto'))
                    data.add_field('improvement_threshold', str(threshold))
                    data.add_field('max_iterations', str(config.get('max_iterations', 50)))
                    data.add_field('learning_rate', str(config.get('learning_rate', 0.1)))
                    data.add_field('rotation_step', str(config.get('rotation_step', 15)))
                    data.add_field('max_rotations', str(config.get('max_rotations', 24)))
                    
                    logger.debug(f"üéØ Enviando threshold a APISLICER: {threshold}")
                    
                    # Llamar a APISLICER con timeout
                    timeout = aiohttp.ClientTimeout(total=120)
                    async with session.post(
                        'http://apislicer:8000/auto-rotate-upload',
                        data=data,
                        timeout=timeout
                    ) as response:
                        if response.status == 200:
                            rotated_bytes = await response.read()
                            
                            # Extraer metadata de headers
                            rotation_info = {
                                "applied": response.headers.get('X-Rotation-Applied', 'false').lower() == 'true',
                                "degrees": json.loads(response.headers.get('X-Rotation-Degrees', '[0,0,0]')),
                                "improvement": float(response.headers.get('X-Improvement-Percentage', '0')),
                                "contact_area": float(response.headers.get('X-Contact-Area', '0')),
                                "original_area": float(response.headers.get('X-Original-Area', '0'))
                            }
                            
                            return rotated_bytes, rotation_info
                        else:
                            error_text = await response.text()
                            raise Exception(f"APISLICER HTTP {response.status}: {error_text}")
            
            except asyncio.TimeoutError as e:
                last_exception = e
                logger.warning(
                    f"      ‚è±Ô∏è  Timeout rotando {filename}, "
                    f"intento {attempt+1}/{self.max_retries}"
                )
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)
            
            except Exception as e:
                last_exception = e
                logger.warning(
                    f"      ‚ö†Ô∏è  Error rotando {filename}: {str(e)}, "
                    f"intento {attempt+1}/{self.max_retries}"
                )
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)
        
        # Si todos los intentos fallaron, lanzar excepci√≥n
        raise Exception(f"Fall√≥ despu√©s de {self.max_retries} intentos: {str(last_exception)}")
    
    async def _slice_file_with_retry(
        self, 
        file_bytes: bytes, 
        filename: str, 
        profile_config: Dict[str, Any]
    ) -> bytes:
        """
        Llama a APISLICER para laminar el archivo con retry logic.
        
        Args:
            file_bytes: Contenido del archivo STL (rotado o original)
            filename: Nombre del archivo
            profile_config: Configuraci√≥n del perfil de laminado
            
        Returns:
            Bytes del archivo G-code generado
        """
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    data = aiohttp.FormData()
                    data.add_field('file', file_bytes, filename=filename, content_type='application/octet-stream')
                    data.add_field('custom_profile', profile_config.get('job_id', ''))
                    
                    timeout = aiohttp.ClientTimeout(total=180)
                    async with session.post(
                        'http://apislicer:8000/slice',
                        data=data,
                        timeout=timeout
                    ) as response:
                        if response.status == 200:
                            return await response.read()
                        else:
                            error_text = await response.text()
                            raise Exception(f"APISLICER HTTP {response.status}: {error_text}")
            
            except asyncio.TimeoutError as e:
                last_exception = e
                logger.warning(
                    f"      ‚è±Ô∏è  Timeout laminando {filename}, "
                    f"intento {attempt+1}/{self.max_retries}"
                )
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)
            
            except Exception as e:
                last_exception = e
                logger.warning(
                    f"      ‚ö†Ô∏è  Error laminando {filename}: {str(e)}, "
                    f"intento {attempt+1}/{self.max_retries}"
                )
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)
        
        # Si todos los intentos fallaron, lanzar excepci√≥n
        raise Exception(f"Laminado fall√≥ despu√©s de {self.max_retries} intentos: {str(last_exception)}")
    
    def get_task_status(self, task_id: str) -> Optional[TaskStatus]:
        """
        Obtiene el estado actual de una tarea.
        
        Args:
            task_id: ID de la tarea
            
        Returns:
            TaskStatus si existe, None si no
        """
        return self.tasks.get(task_id)
    
    def cleanup_old_tasks(self, max_age_hours: int = 24):
        """
        Limpia tareas antiguas del registro para liberar memoria.
        
        Args:
            max_age_hours: Edad m√°xima en horas para mantener tareas
        """
        now = datetime.now()
        tasks_to_remove = []
        
        for task_id, task in self.tasks.items():
            if task.completed_at:
                age_hours = (now - task.completed_at).total_seconds() / 3600
                if age_hours > max_age_hours:
                    tasks_to_remove.append(task_id)
        
        for task_id in tasks_to_remove:
            del self.tasks[task_id]
        
        if tasks_to_remove:
            logger.info(f"üßπ Limpiadas {len(tasks_to_remove)} tareas antiguas")


# Instancia global del worker
# Se inicializa con configuraci√≥n desde variables de entorno o valores por defecto
rotation_worker = RotationWorker(
    max_concurrent=int(os.getenv('ROTATION_WORKER_POOL_SIZE', '3')),
    max_retries=int(os.getenv('ROTATION_MAX_RETRIES', '3')),
    retry_delay=int(os.getenv('ROTATION_RETRY_DELAY', '2'))
)

logger.info("‚úÖ RotationWorker global inicializado")
